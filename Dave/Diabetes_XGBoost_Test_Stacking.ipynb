{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DiabetesTakingMed = pd.read_csv('DiabetesTakingMed.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DiabetesTrain3 = DiabetesTakingMed[DiabetesTakingMed['IsTrain']==1].drop('IsTrain', axis=1)\n",
    "DiabetesTrain3.index = list(range(len(DiabetesTrain3)))\n",
    "\n",
    "DiabetesTest3 = DiabetesTakingMed[DiabetesTakingMed['IsTrain']==0].drop('IsTrain', axis=1)\n",
    "DiabetesTest3.index = list(range(len(DiabetesTest3)))\n",
    "\n",
    "trainX3 = DiabetesTrain3.drop('readmitted', axis=1)\n",
    "trainY3 = DiabetesTrain3['readmitted'].replace([2, 1], [1, 0])\n",
    "\n",
    "testX3 = DiabetesTest3.drop('readmitted', axis=1)\n",
    "testY3 = DiabetesTest3['readmitted'].replace([2, 1], [1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import and run the model:\n",
    "import xgboost\n",
    "from xgboost.sklearn import XGBClassifier as xgb\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import roc_auc_score as AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators=200, min_child_Weight=10, max_depth=5, gamma=5, colsample_bytree=0.6\n"
     ]
    }
   ],
   "source": [
    "'''xgb = xgb()\n",
    "\n",
    "params = {\n",
    "        'n_estimators':[200, 400, 600, 800, 1000],\n",
    "        'min_child_weight': [1, 2, 5, 10],\n",
    "        'gamma': [0.1, 0.2, 0.5, 1, 1.5, 2, 5],\n",
    "        'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "        'max_depth': [2, 3, 5, 8]\n",
    "        }\n",
    "\n",
    "random_search = RandomizedSearchCV(xgb, param_distributions=params, n_iter=100, scoring='roc_auc', n_jobs=6, \n",
    "                                   cv=4, verbose=5, random_state=42)\n",
    "\n",
    "random_search.fit(trainX2, trainY2)\n",
    "\n",
    "random_search.best_params_'''\n",
    "\n",
    "print(\"n_estimators=200, min_child_Weight=10, max_depth=5, gamma=5, colsample_bytree=0.6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dave\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "from xgboost.sklearn import XGBClassifier as xgb\n",
    "\n",
    "xgbF = xgb()\n",
    "xgbF.set_params(n_estimators=200, min_child_weight=10, max_depth=5, gamma=5, colsample_bytree=0.6)\n",
    "\n",
    "xgbF.fit(trainX3, trainY3)\n",
    "\n",
    "predict = xgbF.predict(testX3)\n",
    "predictprobs = xgbF.predict_proba(testX3)\n",
    "\n",
    "#Make feature importances list:\n",
    "AnyChangeXGBFeatures = pd.DataFrame({'Feature':pd.Series(trainX3.columns), 'Importance':xgbF.feature_importances_})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.92972445, 0.07027554],\n",
       "       [0.9098509 , 0.09014908],\n",
       "       [0.8505523 , 0.1494477 ],\n",
       "       ...,\n",
       "       [0.9491745 , 0.05082546],\n",
       "       [0.9068813 , 0.09311873],\n",
       "       [0.9207904 , 0.07920964]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictprobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6749736534379563"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#0.673 better than the 0.66 we had with other methods.\n",
    "AUC(testY3, predictprobs[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09557876216512425"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import brier_score_loss as BSL\n",
    "\n",
    "#0.0956 for XGBoost lower than the stack of logistic and RF (0.09589)\n",
    "BSL(testY3, predictprobs[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subsample=1, max_delta_step=5, learning_rate=0.1\n"
     ]
    }
   ],
   "source": [
    "'''#Let's randomsearch for additional parameters:\n",
    "\n",
    "xgbG = xgb()\n",
    "xgbG.set_params(n_estimators=200, min_child_weight=10, max_depth=5, gamma=5, colsample_bytree=0.6)\n",
    "\n",
    "params2 = {\n",
    "        'learning_rate':[0.0001, 0.001, 0.01, 0.1, 0.2, 0.3],\n",
    "        'max_delta_step': [0, 1, 2, 5, 8],\n",
    "        'subsample':[0.5, 0.6, 0.7, 0.8, 0.9, 1]\n",
    "        }\n",
    "\n",
    "random_search2 = RandomizedSearchCV(xgbG, param_distributions=params2, n_iter=60, scoring='roc_auc', n_jobs=6, \n",
    "                                   cv=4, verbose=5, random_state=42)\n",
    "\n",
    "random_search2.fit(trainX2, trainY2)\n",
    "\n",
    "random_search2.best_params_'''\n",
    "\n",
    "print(\"subsample=1, max_delta_step=5, learning_rate=0.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dave\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "xgbF2 = xgb()\n",
    "xgbF2.set_params(n_estimators=200, min_child_weight=10, max_depth=5, gamma=5, colsample_bytree=0.6, max_delta_step=5)\n",
    "\n",
    "xgbF2.fit(trainX3, trainY3)\n",
    "\n",
    "predict = xgbF2.predict(testX3)\n",
    "predictprobs = xgbF2.predict_proba(testX3)\n",
    "\n",
    "#Make feature importances list:\n",
    "AnyChangeXGBFeatures = pd.DataFrame({'Feature':pd.Series(trainX3.columns), 'Importance':xgbF2.feature_importances_})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6749736534379563"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This is literally the same AUC score. It would seem that not a simgle tree had an altered prediction.\n",
    "AUC(testY3, predictprobs[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "AnyChangeXGBFeatures.sort_values('Importance', ascending=False)\n",
    "ChoiceColumns = list(AnyChangeXGBFeatures[AnyChangeXGBFeatures['Importance']>0]['Feature'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dave\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "trainX3C = trainX3[ChoiceColumns]\n",
    "testX3C = testX3[ChoiceColumns]\n",
    "\n",
    "xgbF2C = xgb()\n",
    "xgbF2C.set_params(n_estimators=500, min_child_weight=10, max_depth=5, gamma=5, colsample_bytree=0.6, max_delta_step=5)\n",
    "\n",
    "xgbF2C.fit(trainX3, trainY3)\n",
    "\n",
    "predictC = xgbF2C.predict(testX3)\n",
    "predictprobsC = xgbF2C.predict_proba(testX3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6753665800254492"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#I also raised N_estimators as there is rarely a penalty for doing this, and it helped raise test AUC.\n",
    "AUC(testY3, predictprobsC[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09555372008645409"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import brier_score_loss as BSL\n",
    "\n",
    "BSL(testY3, predictprobsC[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Summary: XGB: 0.6754, 0.09555"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier as rfc\n",
    "\n",
    "rfc = rfc()\n",
    "rfc.set_params(n_estimators=200, min_samples_split=5, min_samples_leaf=1, max_features='sqrt', max_depth=60)\n",
    "\n",
    "rfc.fit(trainX3, trainY3)\n",
    "predictprobs = rfc.predict_proba(trainX3)\n",
    "predictvalues = rfc.predict(trainX3)\n",
    "actual = trainY3.values\n",
    "\n",
    "R2 = rfc.score(trainX3, trainY3)\n",
    "#Run a test on the completely untouched test 20%\n",
    "TestR2 = rfc.score(testX3, testY3)\n",
    "\n",
    "predicttestRF = rfc.predict(testX3)\n",
    "predicttestprobsRF = rfc.predict_proba(testX3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6542464474137797"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AUC(testY3, predicttestprobsRF[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09661379921141608"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BSL(testY3, predicttestprobsRF[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Summary:  XGB: 0.6754, 0.09555\n",
    "#           RF: 0.6542, 0.09661"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression as lgr\n",
    "\n",
    "lgr = lgr()\n",
    "lgr.set_params(C=0.1)\n",
    "\n",
    "lgr.fit(trainX3, trainY3)\n",
    "predictprobs = lgr.predict_proba(trainX3)\n",
    "predictvalues = lgr.predict(trainX3)\n",
    "actual = trainY3.values\n",
    "\n",
    "R2 = lgr.score(trainX3, trainY3)\n",
    "#Run a test on the completely untouched test 20%\n",
    "TestR2 = lgr.score(testX3, testY3)\n",
    "\n",
    "predicttestLR = lgr.predict(testX3)\n",
    "predicttestprobsLR = lgr.predict_proba(testX3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6633660039876829"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AUC(testY3, predicttestprobsLR[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09661711502693517"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BSL(testY3, predicttestprobsLR[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Summary:  XGB: 0.6754, 0.09555\n",
    "#           RF: 0.6542, 0.09661\n",
    "#     Logistic: 0.6634, 0.09662"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6740965918038246"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Stack = predictprobsC[:,1]/3 + predicttestprobsRF[:,1]/3 + predicttestprobsLR[:,1]/3\n",
    "AUC(testY3, Stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "Stack2 = predictprobsC[:,1]/2 + predicttestprobsLR[:,1]/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6747721319613459"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AUC(testY3, Stack2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can write a function to find a candidate feature list using AIC engineering:\n",
    "\n",
    "def FindLowestAICNonLogBackward(df, dependent):\n",
    "    '''Input: DF to AIC-modify and the dependent variable. WILL RETURN: A tuple: [0] is the modified DF (with dependent)\n",
    "    and tuple[1] will give you the summary DF'''\n",
    "    df2 = df.copy()\n",
    "    df2X = df2.drop(dependent, axis=1)\n",
    "    df2Y = df2[dependent]\n",
    "    FeatureList = list(df2X.columns)\n",
    "    X2 = sm.add_constant(df2X)\n",
    "    est = sm.OLS(df2Y, X2)\n",
    "    CurrentAIC = est.fit().aic\n",
    "    CanBeBetter = True\n",
    "    ModList = []\n",
    "    AddedSubtracted = []\n",
    "    AIC = []\n",
    "    TriesSinceReset = 0\n",
    "    \n",
    "    tempColumnList = list(df2X.columns)\n",
    "    tempDF2X = df2X[tempColumnList]\n",
    "    \n",
    "    while CanBeBetter == True:\n",
    "        Choice = np.random.choice(list(df2X.columns))\n",
    "        \n",
    "        HeadsTails = np.random.randint(2)\n",
    "        if Choice in tempColumnList:\n",
    "            HeadsTails = 0\n",
    "        if Choice not in tempColumnList:\n",
    "            HeadsTails = 1\n",
    "        \n",
    "        if HeadsTails == 1:\n",
    "            tempColumnList.append(Choice)\n",
    "            tempDF2X[Choice] = df2X[Choice]\n",
    "        \n",
    "        if HeadsTails == 0:\n",
    "\n",
    "            tempColumnList.remove(Choice)\n",
    "            tempDF2X = tempDF2X[tempColumnList]\n",
    "            \n",
    "        est = sm.OLS(df2Y, sm.add_constant(tempDF2X))\n",
    "        NewAIC = est.fit().aic\n",
    "        \n",
    "        if NewAIC < CurrentAIC:\n",
    "            TriesSinceReset = 0\n",
    "            CurrentAIC = NewAIC\n",
    "            \n",
    "            if HeadsTails == 1:\n",
    "                print(Choice + \" added: New AIC = \" + str(CurrentAIC))\n",
    "                ModList.append(Choice)\n",
    "                AddedSubtracted.append('Added')\n",
    "                AIC.append(CurrentAIC)\n",
    "                \n",
    "            if HeadsTails == 0:\n",
    "                print(Choice + \" removed: New AIC = \" + str(CurrentAIC))\n",
    "                ModList.append(Choice)\n",
    "                AddedSubtracted.append('Subtracted')\n",
    "                AIC.append(CurrentAIC)\n",
    "            continue\n",
    "            \n",
    "        else:\n",
    "            TriesSinceReset += 1\n",
    "            \n",
    "            if HeadsTails == 1:\n",
    "                tempColumnList.remove(Choice)\n",
    "                tempDF2X = tempDF2X[tempColumnList]\n",
    "                \n",
    "            if HeadsTails == 0:\n",
    "                tempColumnList.append(Choice)\n",
    "                tempDF2X[Choice] = df2X[Choice]\n",
    "                \n",
    "            if TriesSinceReset > 100:\n",
    "                CanBeBetter = False\n",
    "                \n",
    "    SummaryDF = pd.DataFrame({'Feature': ModList, 'AddOrSubtract': AddedSubtracted, 'AIC': AIC})\n",
    "    NewDF = pd.concat([tempDF2X, df2[[dependent]]], axis=1)\n",
    "    \n",
    "    return NewDF, SummaryDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "med_nateglinide removed: New AIC = 159715.59739305108\n",
      "med_glimepiride removed: New AIC = 159714.7314944843\n",
      "diag_injury removed: New AIC = 159713.04955270758\n",
      "med_glipizide.metformin removed: New AIC = 159711.19338007295\n",
      "med_glyburide.metformin removed: New AIC = 159709.48548520193\n",
      "diag_nan removed: New AIC = 159707.58361580828\n",
      "diag_infection removed: New AIC = 159707.17721194788\n",
      "max_glu_serum_>200 removed: New AIC = 159705.39239771228\n",
      "med_chlorpropamide removed: New AIC = 159703.39311154024\n",
      "admission_type_id_3 removed: New AIC = 159701.60665614\n",
      "diag_blooddis removed: New AIC = 159700.3146857473\n",
      "diag_urogenital removed: New AIC = 159698.40742849838\n",
      "admission_type_id_4 removed: New AIC = 159696.6744639213\n",
      "diabfeat_hyperosmolarity removed: New AIC = 159695.31432077044\n",
      "med_miglitol removed: New AIC = 159694.51859519398\n",
      "med_tolazamide removed: New AIC = 159693.06082870622\n",
      "race_AfricanAmerican removed: New AIC = 159691.99226043737\n",
      "med_glyburide removed: New AIC = 159690.25691047826\n",
      "discharge_disposition_unknown removed: New AIC = 159688.6553045108\n",
      "change_Ch removed: New AIC = 159688.13542610875\n",
      "med_pioglitazone removed: New AIC = 159686.37947294395\n",
      "med_rosiglitazone removed: New AIC = 159685.88440346305\n",
      "diabfeat_coma removed: New AIC = 159683.9716018801\n",
      "diag_mentaldis removed: New AIC = 159682.04400334507\n",
      "diag_other removed: New AIC = 159680.15270648606\n",
      "med_tolbutamide removed: New AIC = 159678.40452097228\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "DiabetesTakingMed = pd.read_csv('DiabetesTakingMed.csv', index_col=0)\n",
    "DiabetesTrain3 = DiabetesTakingMed[DiabetesTakingMed['IsTrain']==1].drop('IsTrain', axis=1)\n",
    "DiabetesTrain3.index = list(range(len(DiabetesTrain3)))\n",
    "\n",
    "DiabetesAICTest01 = FindLowestAICNonLogBackward(DiabetesTrain3, 'readmitted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "DiabetesTrain3Cut = DiabetesTrain3[list(DiabetesAICTest01[0].columns)]\n",
    "DiabetesTest3Cut = DiabetesTest3[list(DiabetesAICTest01[0].columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression as lgr\n",
    "\n",
    "lgr = lgr()\n",
    "lgr.set_params(C=0.1)\n",
    "\n",
    "trainX3 = DiabetesTrain3Cut.drop('readmitted', axis=1)\n",
    "trainY3 = DiabetesTrain3Cut['readmitted'].replace([2, 1], [1, 0])\n",
    "\n",
    "testX3 = DiabetesTest3Cut.drop('readmitted', axis=1)\n",
    "testY3 = DiabetesTest3Cut['readmitted'].replace([2, 1], [1, 0])\n",
    "\n",
    "lgr.fit(trainX3, trainY3)\n",
    "predictprobs = lgr.predict_proba(trainX3)\n",
    "predictvalues = lgr.predict(trainX3)\n",
    "actual = trainY3.values\n",
    "\n",
    "R2 = lgr.score(trainX3, trainY3)\n",
    "#Run a test on the completely untouched test 20%\n",
    "TestR2 = lgr.score(testX3, testY3)\n",
    "\n",
    "predicttestLR = lgr.predict(testX3)\n",
    "predicttestprobsLR = lgr.predict_proba(testX3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6616445605479241"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AUC(testY3, predicttestprobsLR[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression as lgr\n",
    "\n",
    "lgr = lgr()\n",
    "lgr.set_params(C=0.1)\n",
    "\n",
    "trainX3 = DiabetesTrain3.drop('readmitted', axis=1)\n",
    "trainY3 = DiabetesTrain3['readmitted'].replace([2, 1], [1, 0])\n",
    "\n",
    "testX3 = DiabetesTest3.drop('readmitted', axis=1)\n",
    "testY3 = DiabetesTest3['readmitted'].replace([2, 1], [1, 0])\n",
    "\n",
    "lgr.fit(trainX3, trainY3)\n",
    "predictprobs = lgr.predict_proba(trainX3)\n",
    "predictvalues = lgr.predict(trainX3)\n",
    "actual = trainY3.values\n",
    "\n",
    "R2 = lgr.score(trainX3, trainY3)\n",
    "#Run a test on the completely untouched test 20%\n",
    "TestR2 = lgr.score(testX3, testY3)\n",
    "\n",
    "predicttestLR = lgr.predict(testX3)\n",
    "predicttestprobsLR = lgr.predict_proba(testX3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6633660039876829"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AUC(testY3, predicttestprobsLR[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier as rfc\n",
    "\n",
    "DiabetesTrain3 = DiabetesTakingMed[DiabetesTakingMed['IsTrain']==1].drop('IsTrain', axis=1)\n",
    "DiabetesTrain3.index = list(range(len(DiabetesTrain3)))\n",
    "\n",
    "DiabetesTest3 = DiabetesTakingMed[DiabetesTakingMed['IsTrain']==0].drop('IsTrain', axis=1)\n",
    "DiabetesTest3.index = list(range(len(DiabetesTest3)))\n",
    "\n",
    "trainX3 = DiabetesTrain3.drop('readmitted', axis=1)\n",
    "trainY3 = DiabetesTrain3['readmitted'].replace([2, 1], [1, 0])\n",
    "\n",
    "testX3 = DiabetesTest3.drop('readmitted', axis=1)\n",
    "testY3 = DiabetesTest3['readmitted'].replace([2, 1], [1, 0])\n",
    "\n",
    "rfc = rfc()\n",
    "rfc.set_params(n_estimators=200, min_samples_split=5, min_samples_leaf=1, max_features='sqrt', max_depth=60)\n",
    "\n",
    "rfc.fit(trainX3, trainY3)\n",
    "predictprobs = rfc.predict_proba(trainX3)\n",
    "predictvalues = rfc.predict(trainX3)\n",
    "actual = trainY3.values\n",
    "\n",
    "R2 = rfc.score(trainX3, trainY3)\n",
    "#Run a test on the completely untouched test 20%\n",
    "TestR2 = rfc.score(testX3, testY3)\n",
    "\n",
    "predicttestRF = rfc.predict(testX3)\n",
    "predicttestprobsRF = rfc.predict_proba(testX3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression as lgr\n",
    "\n",
    "lgr2 = lgr()\n",
    "lgr2.set_params(C=.001)\n",
    "\n",
    "lgr2.fit(predictprobs[:,1].reshape(-1,1),trainY3)\n",
    "\n",
    "predictprobsP = lgr2.predict_proba(predictprobs[:,1].reshape(-1,1))\n",
    "predictvaluesP = lgr2.predict(predictprobs[:,1].reshape(-1,1))\n",
    "actual = trainY3.values\n",
    "\n",
    "R2P = lgr2.score(predictprobs[:,1].reshape(-1,1), trainY3)\n",
    "#Run a test on the completely untouched test 20%\n",
    "TestR2P = lgr2.score(predicttestprobsRF[:,1].reshape(-1,1), testY3)\n",
    "\n",
    "predicttestP = lgr2.predict(predicttestprobsRF[:,1].reshape(-1,1))\n",
    "predicttestprobsP = lgr2.predict_proba(predicttestprobsRF[:,1].reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6581878628455864"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AUC(testY3, predicttestprobsP[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09848271548914546"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BSL(testY3, predicttestprobsP[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01586507, 0.01284292, 0.0445713 , ..., 0.01226695, 0.01523655,\n",
       "       0.01666233])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicttestprobsP[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.11102381, 0.09992857, 0.16601389, ..., 0.09752381, 0.10889881,\n",
       "       0.11360317])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicttestprobsRF[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier as rfc\n",
    "\n",
    "rfc2 = rfc()\n",
    "rfc2.set_params(n_estimators=200, min_samples_split=5, min_samples_leaf=1, max_features='sqrt', max_depth=60)\n",
    "\n",
    "rfc2.fit(predictprobs[:,1].reshape(-1,1),trainY3)\n",
    "\n",
    "predictprobsPP = rfc2.predict_proba(predictprobs[:,1].reshape(-1,1))\n",
    "predictvaluesPP = rfc2.predict(predictprobs[:,1].reshape(-1,1))\n",
    "actual = trainY3.values\n",
    "\n",
    "R2PP = rfc2.score(predictprobs[:,1].reshape(-1,1), trainY3)\n",
    "#Run a test on the completely untouched test 20%\n",
    "TestR2PP = rfc2.score(predicttestprobsRF[:,1].reshape(-1,1), testY3)\n",
    "\n",
    "predicttestPP = rfc2.predict(predicttestprobsRF[:,1].reshape(-1,1))\n",
    "predicttestprobsPP = rfc2.predict_proba(predicttestprobsRF[:,1].reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5453189381416222"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AUC(testY3, predicttestprobsPP[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicttestprobsPP[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1e400955438>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(predictprobs[:,1], actual)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
