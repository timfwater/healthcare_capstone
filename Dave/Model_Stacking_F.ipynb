{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We know (from Model_Parameter_Testing_F) that removing middle observations (came back >30 days) with linear regression score >0.75 (look strongly like those who returned <30 days) helps the model. We need to do this to create our final stacked model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DiabetesTakingMed = pd.read_csv('DiabetesTakingMedF.csv', index_col=0)\n",
    "\n",
    "DiabetesTrain = DiabetesTakingMed[DiabetesTakingMed['IsTrain']==1].drop('IsTrain', axis=1)\n",
    "DiabetesTrain.index = list(range(len(DiabetesTrain)))\n",
    "\n",
    "DiabetesTest = DiabetesTakingMed[DiabetesTakingMed['IsTrain']==0].drop('IsTrain', axis=1)\n",
    "DiabetesTest.index = list(range(len(DiabetesTest)))\n",
    "\n",
    "#Start with a train to predict the placement of the middle group:\n",
    "\n",
    "DiabetesTrainHL = DiabetesTrain[DiabetesTrain['readmitted']!=1]\n",
    "trainX01 = DiabetesTrainHL.drop('readmitted', axis=1)\n",
    "trainY01 = DiabetesTrainHL['readmitted'].replace([2], [1])\n",
    "\n",
    "testX01 = DiabetesTest.drop('readmitted', axis=1)\n",
    "testY01 = DiabetesTest['readmitted'].replace([2], [1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression as lm\n",
    "\n",
    "lm = lm()\n",
    "\n",
    "lm.fit(trainX01, trainY01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "middledf = DiabetesTrain[DiabetesTrain['readmitted']==1]\n",
    "middledfX = middledf.drop('readmitted', axis=1)\n",
    "middledfY = middledf['readmitted']\n",
    "\n",
    "predictarray = lm.predict(middledfX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "middledf75 = middledf.loc[predictarray<0.75]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make the complete dataset with intermediate observations >0.75 removed:\n",
    "\n",
    "train75 = pd.concat([DiabetesTrainHL, middledf75], axis=0)\n",
    "train75.index = list(range(len(train75)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split this now-complete DF into X (features) and Y (output) objects:\n",
    "\n",
    "trainX = train75.drop('readmitted', axis=1)\n",
    "trainY = train75['readmitted'].replace([2, 1], [1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#As seen in other runs, trimming based on AIC does not improve the model. (0.6646 vs 0.66735)\n",
    "#Based on this, the best score we have is 0.66735, based on keeping >0.75 predictions of the >30 return train group. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove specific features (found in Model_Parameter_Testing_F) that improve the logistic regression:\n",
    "\n",
    "TrainLR = train75.drop(['diabfeat_neurologic', 'race_AfricanAmerican', 'A1Cresult_>7', 'primarydiag_injury', 'number_diagnoses', \n",
    "    'med_glimepiride', 'med_insulin', 'diag_infection', 'medical_specialty_Orthopedics', 'med_nateglinide', 'discharge_disposition_leftAMA', \n",
    "    'admission_source_id_3', 'change_Ch', 'diag_circulatory', 'medical_specialty_Gastroenterology', 'medical_specialty_Surgery',\n",
    "    'primarydiag_infection', 'primarydiag_mentaldis'], axis=1)\n",
    "TrainLRX = TrainLR.drop('readmitted', axis=1)\n",
    "TrainLRY = TrainLR['readmitted'].replace([2,1], [1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the logistic regression with the optimal parameteres\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression as lgr\n",
    "\n",
    "lgr = lgr()\n",
    "lgr.set_params(C=0.1, class_weight={0:.2, 1:.8})\n",
    "\n",
    "lgr.fit(TrainLRX, TrainLRY)\n",
    "predictprobsLRW = lgr.predict_proba(testX01)\n",
    "\n",
    "from sklearn.metrics import roc_auc_score as AUC\n",
    "\n",
    "AUC(testY03, predictprobsLRW[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dave\\Anaconda3\\lib\\importlib\\_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6706926578913641"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Perform logistic regression with optimal conditions:\n",
    "from sklearn.ensemble import RandomForestClassifier as rfc\n",
    "\n",
    "rfc = rfc()\n",
    "rfc.set_params(n_estimators=1000, min_samples_split=5, min_samples_leaf=1, max_features='sqrt', \n",
    "               max_depth=60, random_state=42, class_weight={0:.2, 1:.8})\n",
    "\n",
    "rfc.fit(trainX, trainY)\n",
    "\n",
    "predictRFW = rfc.predict(testX03)\n",
    "predictprobsRFW5 = rfc.predict_proba(testX03)\n",
    "\n",
    "from sklearn.metrics import roc_auc_score as AUC\n",
    "\n",
    "AUC(testY03, predictprobsRFW[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using class weights, we very slightly increased the output from LR to 0.66774\n",
    "\n",
    "# AUC of 0.66774 for class-weighted logistic regression\n",
    "# AUC of 0.68011 for parameter-optimized XGBoost\n",
    "# AUC of 0.67069 for class-weighted hyperparameter-optimized random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dave\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "#Now let's try enhaning the XGB score using scale_pos_weight (the # of negative samples/# positive)\n",
    "\n",
    "from xgboost.sklearn import XGBClassifier as xgb\n",
    "\n",
    "xgb = xgb()\n",
    "xgb.set_params(n_estimators=500, min_child_weight=10, max_depth=5, gamma=5, colsample_bytree=0.6, max_delta_step=5,\n",
    "              random_state=42, scale_pos_weight=4)\n",
    "\n",
    "xgb.fit(trainX, trainY)\n",
    "\n",
    "predictXBW = xgb.predict(testX03)\n",
    "predictprobsXBW = xgb.predict_proba(testX03)\n",
    "\n",
    "AUC(testY03, predictprobsXBW[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dave\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6801164864800598"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import the XGB model with optimal parameters:\n",
    "\n",
    "from xgboost.sklearn import XGBClassifier as xgb\n",
    "\n",
    "xgb = xgb()\n",
    "xgb.set_params(n_estimators=500, min_child_weight=10, max_depth=5, gamma=5, colsample_bytree=0.6, max_delta_step=5,\n",
    "              random_state=42, scale_pos_weight=1)\n",
    "\n",
    "xgb.fit(trainX, trainY)\n",
    "\n",
    "predictXBW = xgb.predict(testX03)\n",
    "predictprobsXBW = xgb.predict_proba(testX03)\n",
    "\n",
    "AUC(testY03, predictprobsXBW[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6801164864800598\n",
      "0.6725013797805438\n",
      "0.6706926578913641\n"
     ]
    }
   ],
   "source": [
    "#These are our targets. Let's make sure we have the correct prediction arrays:\n",
    "\n",
    "# AUC of 0.6725 for class-weighted logistic regression\n",
    "# AUC of 0.68011 for parameter-optimized XGBoost\n",
    "# AUC of 0.67069 for class-weighted hyperparameter-optimized random forest\n",
    "\n",
    "#let's make sure we have the correct 3 prediction arrays:\n",
    "print(AUC(testY03, predictprobsXBW[:,1]))\n",
    "print(AUC(testY03, predictprobsLRW[:,1]))\n",
    "print(AUC(testY03, predictprobsRFW[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "StackDFScores = []\n",
    "RFPercents = []\n",
    "LGPercents = []\n",
    "XGPercents = []\n",
    "\n",
    "AUC(testY03, predictprobsRFW5[:,1])\n",
    "AUC(testY03, predictprobsvartest[:,1])\n",
    "AUC(testY03, predictprobsXBW[:,1])\n",
    "\n",
    "for i in range(101):\n",
    "    for j in range(101):\n",
    "        for k in range(101):\n",
    "            if i + j + k == 100:\n",
    "                StackPredict = AUC(testY03, (k*predictprobsRFW5[:,1] + i*predictprobsvartest[:,1] + \n",
    "                                j*predictprobsXBW[:,1])/100)\n",
    "                StackDFScores.append(StackPredict)\n",
    "                RFPercents.append(k)\n",
    "                LGPercents.append(i)\n",
    "                XGPercents.append(j)\n",
    "\n",
    "StackDF = pd.DataFrame({'Score':pd.Series(StackDFScores), 'LogRegPct':pd.Series(LGPercents),\n",
    "                       'RFPercents':pd.Series(RFPercents), 'XGPercents':pd.Series(XGPercents)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "      <th>LogRegPct</th>\n",
       "      <th>RFPercents</th>\n",
       "      <th>XGPercents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1967</th>\n",
       "      <td>0.684145</td>\n",
       "      <td>21</td>\n",
       "      <td>23</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1887</th>\n",
       "      <td>0.684141</td>\n",
       "      <td>20</td>\n",
       "      <td>23</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1966</th>\n",
       "      <td>0.684141</td>\n",
       "      <td>21</td>\n",
       "      <td>24</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1885</th>\n",
       "      <td>0.684140</td>\n",
       "      <td>20</td>\n",
       "      <td>25</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1886</th>\n",
       "      <td>0.684138</td>\n",
       "      <td>20</td>\n",
       "      <td>24</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1806</th>\n",
       "      <td>0.684137</td>\n",
       "      <td>19</td>\n",
       "      <td>23</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1965</th>\n",
       "      <td>0.684136</td>\n",
       "      <td>21</td>\n",
       "      <td>25</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2046</th>\n",
       "      <td>0.684135</td>\n",
       "      <td>22</td>\n",
       "      <td>23</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1805</th>\n",
       "      <td>0.684135</td>\n",
       "      <td>19</td>\n",
       "      <td>24</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2045</th>\n",
       "      <td>0.684135</td>\n",
       "      <td>22</td>\n",
       "      <td>24</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2044</th>\n",
       "      <td>0.684133</td>\n",
       "      <td>22</td>\n",
       "      <td>25</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1968</th>\n",
       "      <td>0.684133</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1888</th>\n",
       "      <td>0.684131</td>\n",
       "      <td>20</td>\n",
       "      <td>22</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1804</th>\n",
       "      <td>0.684130</td>\n",
       "      <td>19</td>\n",
       "      <td>25</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1884</th>\n",
       "      <td>0.684127</td>\n",
       "      <td>20</td>\n",
       "      <td>26</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1964</th>\n",
       "      <td>0.684126</td>\n",
       "      <td>21</td>\n",
       "      <td>26</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1807</th>\n",
       "      <td>0.684124</td>\n",
       "      <td>19</td>\n",
       "      <td>22</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1969</th>\n",
       "      <td>0.684121</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1724</th>\n",
       "      <td>0.684120</td>\n",
       "      <td>18</td>\n",
       "      <td>23</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2047</th>\n",
       "      <td>0.684119</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2123</th>\n",
       "      <td>0.684118</td>\n",
       "      <td>23</td>\n",
       "      <td>24</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1723</th>\n",
       "      <td>0.684118</td>\n",
       "      <td>18</td>\n",
       "      <td>24</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1889</th>\n",
       "      <td>0.684117</td>\n",
       "      <td>20</td>\n",
       "      <td>21</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1808</th>\n",
       "      <td>0.684115</td>\n",
       "      <td>19</td>\n",
       "      <td>21</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2124</th>\n",
       "      <td>0.684115</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1803</th>\n",
       "      <td>0.684113</td>\n",
       "      <td>19</td>\n",
       "      <td>26</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2043</th>\n",
       "      <td>0.684113</td>\n",
       "      <td>22</td>\n",
       "      <td>26</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1963</th>\n",
       "      <td>0.684112</td>\n",
       "      <td>21</td>\n",
       "      <td>27</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2125</th>\n",
       "      <td>0.684111</td>\n",
       "      <td>23</td>\n",
       "      <td>22</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2122</th>\n",
       "      <td>0.684111</td>\n",
       "      <td>23</td>\n",
       "      <td>25</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>0.672816</td>\n",
       "      <td>4</td>\n",
       "      <td>95</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.672809</td>\n",
       "      <td>0</td>\n",
       "      <td>91</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5148</th>\n",
       "      <td>0.672783</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5149</th>\n",
       "      <td>0.672690</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>0.672603</td>\n",
       "      <td>3</td>\n",
       "      <td>95</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>0.672597</td>\n",
       "      <td>2</td>\n",
       "      <td>94</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>0.672593</td>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>0.672584</td>\n",
       "      <td>4</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.672580</td>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5150</th>\n",
       "      <td>0.672501</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>0.672372</td>\n",
       "      <td>2</td>\n",
       "      <td>95</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>0.672367</td>\n",
       "      <td>1</td>\n",
       "      <td>94</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>0.672365</td>\n",
       "      <td>3</td>\n",
       "      <td>96</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.672351</td>\n",
       "      <td>0</td>\n",
       "      <td>93</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>0.672142</td>\n",
       "      <td>1</td>\n",
       "      <td>95</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>0.672129</td>\n",
       "      <td>2</td>\n",
       "      <td>96</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>0.672129</td>\n",
       "      <td>3</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.672120</td>\n",
       "      <td>0</td>\n",
       "      <td>94</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>0.671905</td>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>0.671905</td>\n",
       "      <td>2</td>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.671890</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>0.671674</td>\n",
       "      <td>1</td>\n",
       "      <td>97</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>0.671668</td>\n",
       "      <td>2</td>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.671654</td>\n",
       "      <td>0</td>\n",
       "      <td>96</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0.671427</td>\n",
       "      <td>1</td>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.671415</td>\n",
       "      <td>0</td>\n",
       "      <td>97</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>0.671187</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.671178</td>\n",
       "      <td>0</td>\n",
       "      <td>98</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.670938</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.670693</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5151 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Score  LogRegPct  RFPercents  XGPercents\n",
       "1967  0.684145         21          23          56\n",
       "1887  0.684141         20          23          57\n",
       "1966  0.684141         21          24          55\n",
       "1885  0.684140         20          25          55\n",
       "1886  0.684138         20          24          56\n",
       "1806  0.684137         19          23          58\n",
       "1965  0.684136         21          25          54\n",
       "2046  0.684135         22          23          55\n",
       "1805  0.684135         19          24          57\n",
       "2045  0.684135         22          24          54\n",
       "2044  0.684133         22          25          53\n",
       "1968  0.684133         21          22          57\n",
       "1888  0.684131         20          22          58\n",
       "1804  0.684130         19          25          56\n",
       "1884  0.684127         20          26          54\n",
       "1964  0.684126         21          26          53\n",
       "1807  0.684124         19          22          59\n",
       "1969  0.684121         21          21          58\n",
       "1724  0.684120         18          23          59\n",
       "2047  0.684119         22          22          56\n",
       "2123  0.684118         23          24          53\n",
       "1723  0.684118         18          24          58\n",
       "1889  0.684117         20          21          59\n",
       "1808  0.684115         19          21          60\n",
       "2124  0.684115         23          23          54\n",
       "1803  0.684113         19          26          55\n",
       "2043  0.684113         22          26          52\n",
       "1963  0.684112         21          27          52\n",
       "2125  0.684111         23          22          55\n",
       "2122  0.684111         23          25          52\n",
       "...        ...        ...         ...         ...\n",
       "399   0.672816          4          95           1\n",
       "9     0.672809          0          91           9\n",
       "5148  0.672783         99           1           0\n",
       "5149  0.672690         99           0           1\n",
       "302   0.672603          3          95           2\n",
       "205   0.672597          2          94           4\n",
       "107   0.672593          1          93           6\n",
       "398   0.672584          4          96           0\n",
       "8     0.672580          0          92           8\n",
       "5150  0.672501        100           0           0\n",
       "204   0.672372          2          95           3\n",
       "106   0.672367          1          94           5\n",
       "301   0.672365          3          96           1\n",
       "7     0.672351          0          93           7\n",
       "105   0.672142          1          95           4\n",
       "203   0.672129          2          96           2\n",
       "300   0.672129          3          97           0\n",
       "6     0.672120          0          94           6\n",
       "104   0.671905          1          96           3\n",
       "202   0.671905          2          97           1\n",
       "5     0.671890          0          95           5\n",
       "103   0.671674          1          97           2\n",
       "201   0.671668          2          98           0\n",
       "4     0.671654          0          96           4\n",
       "102   0.671427          1          98           1\n",
       "3     0.671415          0          97           3\n",
       "101   0.671187          1          99           0\n",
       "2     0.671178          0          98           2\n",
       "1     0.670938          0          99           1\n",
       "0     0.670693          0         100           0\n",
       "\n",
       "[5151 rows x 4 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "StackDF.sort_values('Score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictprob = (56*predictprobsXBW[:,1] + 23*predictprobsRFW5[:,1] + 21*predictprobsvartest[:,1])/100\n",
    "\n",
    "\n",
    "TestValues = pd.DataFrame({'num_lab_procedures':testX03['num_lab_procedures'], 'predict_prob':pd.Series(predictprob)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dave\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "TestValues['predict_actual'] = 0\n",
    "TestValues['predict_actual'][TestValues['predict_prob']>0.5]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6841445976784577"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AUC(testY03, TestValues['predict_prob'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "TestValues.to_csv('TestPredictions.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
