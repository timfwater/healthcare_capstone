{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['encounter_id', 'patient_nbr', 'race', 'gender', 'age', 'weight', 'admission_type_id', 'discharge_disposition_id', 'admission_source_id', 'time_in_hospital', 'payer_code', 'medical_specialty', 'num_lab_procedures', 'num_procedures', 'num_medications', 'number_outpatient', 'number_emergency', 'number_inpatient', 'diag_1', 'diag_2', 'diag_3', 'number_diagnoses', 'max_glu_serum', 'A1Cresult', 'metformin', 'repaglinide', 'nateglinide', 'chlorpropamide', 'glimepiride', 'acetohexamide', 'glipizide', 'glyburide', 'tolbutamide', 'pioglitazone', 'rosiglitazone', 'acarbose', 'miglitol', 'troglitazone', 'tolazamide', 'examide', 'citoglipton', 'insulin', 'glyburide-metformin', 'glipizide-metformin', 'glimepiride-pioglitazone', 'metformin-rosiglitazone', 'metformin-pioglitazone', 'change', 'diabetesMed', 'readmitted']\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"diabetic_data.csv\")\n",
    "print(list(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The encounter_id and patient_nbr are used for identification and are not relevant to whether a patient will return.\n",
    "# The weight and payer code attributes are dropped because of their high percentage of missing values.\n",
    "# This means that neither of them are relevant to the readmission rate.\n",
    "# We can find more information about this in the research paper.\n",
    "df = df.drop(columns=['encounter_id', 'patient_nbr', 'weight', 'payer_code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We remove all columns with patients that expired (died) as we know they cannot be readmitted.\n",
    "# On a side note, theoretically if we had enough data and other features, we could predict whether or not a patient would die\n",
    "# within the thirty days and use that to predict that that patient will not be readmitted.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In each of the following cells, we take a nominal (categorical) column and do the following:\n",
    "- Dummify the column\n",
    "- Remove any columns describing the missingness of that feature\n",
    "- Drop the most common value of that feature if the missingness is not too deep\n",
    "- Add the dummy columns back to the original dataframe and drop the original non-dummified column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caucasian          76099\n",
      "AfricanAmerican    19210\n",
      "?                   2273\n",
      "Hispanic            2037\n",
      "Other               1506\n",
      "Asian                641\n",
      "Name: race, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "races = pd.get_dummies(df['race'])\n",
    "print(df['race'].value_counts())\n",
    "\n",
    "# The most common race of the patients is Caucasian, so we drop that column.\n",
    "# The missingness is sparse enough that we can drop it without losing very much information.\n",
    "# We also drop the Asian column because it so uncommon that it will not factor into our model prediction if we included it.\n",
    "races = races.drop(columns = ['?', 'Caucasian', 'Asian'])\n",
    "\n",
    "# We add the the dummy columns back to the original dataframe\n",
    "df = pd.concat([df, races], axis=1)\n",
    "df = df.drop(columns = ['race'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Female             54708\n",
      "Male               47055\n",
      "Unknown/Invalid        3\n",
      "Name: gender, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "genders = pd.get_dummies(df['gender'])\n",
    "print(df['gender'].value_counts())\n",
    "\n",
    "# The most common gender of the patients is female, so we drop that column.\n",
    "# The missingness is sparse enough that we can drop it without losing very much information.\n",
    "genders = genders.drop(columns = ['Unknown/Invalid', 'Female'])\n",
    "\n",
    "# We add the the dummy column back to the original dataframe\n",
    "df = pd.concat([df, genders], axis=1)\n",
    "df = df.drop(columns = ['gender'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Age nominal column need not be dummified because it can be easily turned into a numerical column as follows:\n",
    "age = df[\"age\"]\n",
    "\n",
    "# We replace each age bin with its lower bound divided by 10\n",
    "for i in range(10):\n",
    "    age = age.replace(\"[\"+str(10*i)+\"-\"+str(10*(i+1))+\")\", i)\n",
    "\n",
    "df['age'] = age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    53990\n",
      "3    18869\n",
      "2    18480\n",
      "6     5291\n",
      "5     4785\n",
      "8      320\n",
      "7       21\n",
      "4       10\n",
      "Name: admission_type_id, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "admission_type = pd.get_dummies(df['admission_type_id'])\n",
    "print(df['admission_type_id'].value_counts())\n",
    "\n",
    "# The most common admission type of the patients is Emergency (1), so we drop that column.\n",
    "# The missingness is sparse enough (about 10%) that we can drop those columns (5, 6, and 8) without losing very much information.\n",
    "admission_type = admission_type.drop(columns = [1, 5, 6, 8])\n",
    "\n",
    "# We add the the dummy columns back to the original dataframe\n",
    "df = pd.concat([df, admission_type], axis=1)\n",
    "df = df.drop(columns = ['admission_type_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1     60234\n",
      "3     13954\n",
      "6     12902\n",
      "18     3691\n",
      "2      2128\n",
      "22     1993\n",
      "11     1642\n",
      "5      1184\n",
      "25      989\n",
      "4       815\n",
      "7       623\n",
      "23      412\n",
      "13      399\n",
      "14      372\n",
      "28      139\n",
      "8       108\n",
      "15       63\n",
      "24       48\n",
      "9        21\n",
      "17       14\n",
      "16       11\n",
      "19        8\n",
      "10        6\n",
      "27        5\n",
      "12        3\n",
      "20        2\n",
      "Name: discharge_disposition_id, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "discharge_disposition = pd.get_dummies(df['discharge_disposition_id'])\n",
    "print(df['discharge_disposition_id'].value_counts())\n",
    "\n",
    "# The most common discharge type of the patients is Discharged to Home (1), so we drop that column.\n",
    "# The missingness is sparse enough (about 4.5%) that we can drop those columns (18 and 25) without losing very much information.\n",
    "discharge_disposition = discharge_disposition.drop(columns = [1, 18, 25])\n",
    "\n",
    "# We add the the dummy columns back to the original dataframe\n",
    "df = pd.concat([df, discharge_disposition], axis=1)\n",
    "df = df.drop(columns = ['discharge_disposition_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7     57494\n",
      "1     29565\n",
      "17     6781\n",
      "4      3187\n",
      "6      2264\n",
      "2      1104\n",
      "5       855\n",
      "3       187\n",
      "20      161\n",
      "9       125\n",
      "8        16\n",
      "22       12\n",
      "10        8\n",
      "11        2\n",
      "14        2\n",
      "25        2\n",
      "13        1\n",
      "Name: admission_source_id, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "admission_source = pd.get_dummies(df['admission_source_id'])\n",
    "print(df['admission_source_id'].value_counts())\n",
    "\n",
    "# The most common route of admission is from the emergency room (7), so we drop that column.\n",
    "# The missingness is sparse enough (about 7%) that we can drop it without losing very much information.\n",
    "admission_source = admission_source.drop(columns = [7, 17, 9, 20])\n",
    "\n",
    "# We add the the dummy columns back to the original dataframe\n",
    "df = pd.concat([df, admission_source], axis=1)\n",
    "df = df.drop(columns = ['admission_source_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "?                                    49949\n",
      "InternalMedicine                     14635\n",
      "Emergency/Trauma                      7565\n",
      "Family/GeneralPractice                7440\n",
      "Cardiology                            5352\n",
      "Surgery-General                       3099\n",
      "Nephrology                            1613\n",
      "Orthopedics                           1400\n",
      "Orthopedics-Reconstructive            1233\n",
      "Radiologist                           1140\n",
      "Pulmonology                            871\n",
      "Psychiatry                             854\n",
      "Urology                                685\n",
      "ObstetricsandGynecology                671\n",
      "Surgery-Cardiovascular/Thoracic        652\n",
      "Gastroenterology                       564\n",
      "Surgery-Vascular                       533\n",
      "Surgery-Neuro                          468\n",
      "PhysicalMedicineandRehabilitation      391\n",
      "Oncology                               348\n",
      "Pediatrics                             254\n",
      "Hematology/Oncology                    207\n",
      "Neurology                              203\n",
      "Pediatrics-Endocrinology               159\n",
      "Otolaryngology                         125\n",
      "Endocrinology                          120\n",
      "Surgery-Thoracic                       109\n",
      "Psychology                             101\n",
      "Podiatry                               100\n",
      "Surgery-Cardiovascular                  98\n",
      "                                     ...  \n",
      "Anesthesiology-Pediatric                19\n",
      "Obstetrics                              19\n",
      "Rheumatology                            17\n",
      "Pathology                               17\n",
      "OutreachServices                        12\n",
      "Anesthesiology                          12\n",
      "PhysicianNotFound                       11\n",
      "Surgery-Maxillofacial                   11\n",
      "Surgery-Colon&Rectal                    11\n",
      "Pediatrics-Neurology                    10\n",
      "Surgery-Pediatric                        8\n",
      "Endocrinology-Metabolism                 8\n",
      "Cardiology-Pediatric                     7\n",
      "AllergyandImmunology                     7\n",
      "Psychiatry-Child/Adolescent              7\n",
      "DCPTEAM                                  6\n",
      "Dentistry                                4\n",
      "Pediatrics-Hematology-Oncology           4\n",
      "Pediatrics-EmergencyMedicine             3\n",
      "Pediatrics-AllergyandImmunology          3\n",
      "Resident                                 2\n",
      "Perinatology                             1\n",
      "Speech                                   1\n",
      "Psychiatry-Addictive                     1\n",
      "Proctology                               1\n",
      "SportsMedicine                           1\n",
      "Neurophysiology                          1\n",
      "Pediatrics-InfectiousDiseases            1\n",
      "Surgery-PlasticwithinHeadandNeck         1\n",
      "Dermatology                              1\n",
      "Name: medical_specialty, Length: 73, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "medical_specialty = pd.get_dummies(df['medical_specialty'])\n",
    "print(df['medical_specialty'].value_counts())\n",
    "\n",
    "# The missingness is rampant in this column (53%). Though we will still drop this column, we cannot drop the most common\n",
    "# non-missing column, Internal Medicine. If we did do this, our model would assume that a missing specialty of the doctor\n",
    "# is really internal medicine, which we do not want. As an aside, sometimes it is okay to impute by the most common class, but\n",
    "# we will not be doing this.\n",
    "\n",
    "# Here we drop the column displaying the missingness.\n",
    "medical_specialty = medical_specialty.drop(columns = ['?'])\n",
    "\n",
    "# As there are 84 medical specialties, we do not wish to try to model every specialty, because there are just too many.\n",
    "# We would require more data, lots of computing power, and potentially a lot of time.\n",
    "# Instead we only model the specialties of doctors that treated at least 1% of patients in our data set.\n",
    "# Of course, 1% is arbitrary.\n",
    "treated_onepercent = list(df['medical_specialty'].value_counts()[1:10].index)\n",
    "medical_specialty = medical_specialty.drop(columns = treated_onepercent)\n",
    "\n",
    "# We add the the dummy columns back to the original dataframe\n",
    "df = pd.concat([df, medical_specialty], axis=1)\n",
    "df = df.drop(columns = ['medical_specialty'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the diagonosis columns we need to perform a more detailed dummification of the variables becuase all three columns need to\n",
    "# be distributed into the various dummified variables.\n",
    "\n",
    "# For the three diagnosis columns, we first change the icd9 codes into the group name of the disease for which the patient was\n",
    "# admitted. The types of diseases are circulatory, respiratory, digestive, diabetes, injury, musculoskeletal, genitourinary,\n",
    "# neoplasms, and other.\n",
    "diagnoses = df[['diag_1', 'diag_2', 'diag_3']]\n",
    "\n",
    "# These are lists of the icd9 codes for illness contained within the nine illness groups\n",
    "circulatory_icd9_codes = list(map(str, range(390, 460))) + ['785']\n",
    "respiratory_icd9_codes = list(map(str, range(460, 520))) + ['786']\n",
    "digestive_icd9_codes = list(map(str, range(520, 580))) + ['787']\n",
    "diabetes_icd9_codes = list(map(str, list(np.linspace(250, 251, 100, endpoint = False)))) + ['250']\n",
    "injury_icd9_codes = list(map(str, range(800, 1000)))\n",
    "musculoskeletal_icd9_codes = list(map(str, range(710, 740)))\n",
    "genitourinary_icd9_codes = list(map(str, range(580, 630))) + ['788']\n",
    "neoplasms_icd9_codes = list(map(str, range(140, 240)))\n",
    "other_codes = (list(map(str, range(1, 800))) + \n",
    "               list(map(lambda x: 'V0' + str(x), range(0, 10))) +\n",
    "               list(map(lambda x: 'V' + str(x), range(10, 100))) + \n",
    "               list(map(lambda x: 'E' + str(x), range(800, 1000))) +\n",
    "               ['365.44']\n",
    "              )\n",
    "# We change the icd9 codes to the respective illness group\n",
    "diagnoses = diagnoses.replace(circulatory_icd9_codes, 'circulatory')\n",
    "diagnoses = diagnoses.replace(respiratory_icd9_codes, 'respiratory')\n",
    "diagnoses = diagnoses.replace(digestive_icd9_codes, 'digestive')\n",
    "diagnoses = diagnoses.replace(diabetes_icd9_codes, 'diabetes')\n",
    "diagnoses = diagnoses.replace(injury_icd9_codes, 'injury')\n",
    "diagnoses = diagnoses.replace(musculoskeletal_icd9_codes, 'musculoskeletal')\n",
    "diagnoses = diagnoses.replace(genitourinary_icd9_codes, 'genitourinary')\n",
    "diagnoses = diagnoses.replace(neoplasms_icd9_codes, 'neoplasms')\n",
    "diagnoses = diagnoses.replace(other_codes, 'other')\n",
    "\n",
    "# Next we dummify and then add the dummifed columns together\n",
    "diag_1 = pd.get_dummies(diagnoses['diag_1'])\n",
    "diag_2 = pd.get_dummies(diagnoses['diag_2'])\n",
    "diag_3 = pd.get_dummies(diagnoses['diag_3'])\n",
    "dummy_diag = diag_1 + diag_2 + diag_3\n",
    "\n",
    "# The missingness is sparse enough that we can drop it without losing very much information.\n",
    "# Since we cannot deduce the illness group of a patient with the other collumns, there is not that much multicollinearity, so\n",
    "# we need not drop the most common column.\n",
    "dummy_diag = dummy_diag.drop(columns = ['?'])\n",
    "\n",
    "# We add the the dummy columns back to the original dataframe\n",
    "df = pd.concat([df, dummy_diag], axis=1)\n",
    "df = df.drop(columns = ['diag_1', 'diag_2', 'diag_3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None    96420\n",
      "Norm     2597\n",
      ">200     1485\n",
      ">300     1264\n",
      "Name: max_glu_serum, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "glu_serum = pd.get_dummies(df['max_glu_serum'])\n",
    "print(df['max_glu_serum'].value_counts())\n",
    "\n",
    "# There is so much missingness (96%) that we need not drop the non-missing column with the most counts because we do not risk\n",
    "# causing multicollinearity.\n",
    "glu_serum = glu_serum.drop(columns = ['None'])\n",
    "\n",
    "# We add the the dummy columns back to the original dataframe\n",
    "df = pd.concat([df, glu_serum], axis=1)\n",
    "df = df.drop(columns = ['max_glu_serum'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None    84748\n",
      ">8       8216\n",
      "Norm     4990\n",
      ">7       3812\n",
      "Name: A1Cresult, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "A1Cresult = pd.get_dummies(df['A1Cresult'])\n",
    "print(df['A1Cresult'].value_counts())\n",
    "\n",
    "# The most common A1C test value is None, indicating that it was not taken. Ordinarily, we would drop the dummified column of\n",
    "# None because we usually can be sure it isn't statistically significant. However, in this case, the conclusion of the research\n",
    "# paper clearly states that whether or not Hemoglobin A1C was measured is very important in predicting readission. Thus it is\n",
    "# imperative that we retain the None column.\n",
    "\n",
    "# We add the the dummy columns back to the original dataframe\n",
    "df = pd.concat([df, A1Cresult], axis=1)\n",
    "df = df.drop(columns = ['A1Cresult'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No        81778\n",
      "Steady    18346\n",
      "Up         1067\n",
      "Down        575\n",
      "Name: metformin, dtype: int64\n",
      "No        100227\n",
      "Steady      1384\n",
      "Up           110\n",
      "Down          45\n",
      "Name: repaglinide, dtype: int64\n",
      "No        101063\n",
      "Steady       668\n",
      "Up            24\n",
      "Down          11\n",
      "Name: nateglinide, dtype: int64\n",
      "No        101680\n",
      "Steady        79\n",
      "Up             6\n",
      "Down           1\n",
      "Name: chlorpropamide, dtype: int64\n",
      "No        96575\n",
      "Steady     4670\n",
      "Up          327\n",
      "Down        194\n",
      "Name: glimepiride, dtype: int64\n",
      "No        101765\n",
      "Steady         1\n",
      "Name: acetohexamide, dtype: int64\n",
      "No        89080\n",
      "Steady    11356\n",
      "Up          770\n",
      "Down        560\n",
      "Name: glipizide, dtype: int64\n",
      "No        91116\n",
      "Steady     9274\n",
      "Up          812\n",
      "Down        564\n",
      "Name: glyburide, dtype: int64\n",
      "No        101743\n",
      "Steady        23\n",
      "Name: tolbutamide, dtype: int64\n",
      "No        94438\n",
      "Steady     6976\n",
      "Up          234\n",
      "Down        118\n",
      "Name: pioglitazone, dtype: int64\n",
      "No        95401\n",
      "Steady     6100\n",
      "Up          178\n",
      "Down         87\n",
      "Name: rosiglitazone, dtype: int64\n",
      "No        101458\n",
      "Steady       295\n",
      "Up            10\n",
      "Down           3\n",
      "Name: acarbose, dtype: int64\n",
      "No        101728\n",
      "Steady        31\n",
      "Down           5\n",
      "Up             2\n",
      "Name: miglitol, dtype: int64\n",
      "No        101763\n",
      "Steady         3\n",
      "Name: troglitazone, dtype: int64\n",
      "No        101727\n",
      "Steady        38\n",
      "Up             1\n",
      "Name: tolazamide, dtype: int64\n",
      "No    101766\n",
      "Name: examide, dtype: int64\n",
      "No    101766\n",
      "Name: citoglipton, dtype: int64\n",
      "No        47383\n",
      "Steady    30849\n",
      "Down      12218\n",
      "Up        11316\n",
      "Name: insulin, dtype: int64\n",
      "No        101060\n",
      "Steady       692\n",
      "Up             8\n",
      "Down           6\n",
      "Name: glyburide-metformin, dtype: int64\n",
      "No        101753\n",
      "Steady        13\n",
      "Name: glipizide-metformin, dtype: int64\n",
      "No        101765\n",
      "Steady         1\n",
      "Name: glimepiride-pioglitazone, dtype: int64\n",
      "No        101764\n",
      "Steady         2\n",
      "Name: metformin-rosiglitazone, dtype: int64\n",
      "No        101765\n",
      "Steady         1\n",
      "Name: metformin-pioglitazone, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# When we examine the 23 different medication features, we find that a bunch of the medications are hardly ever prescribed.\n",
    "\n",
    "print(df['metformin'].value_counts())\n",
    "print(df['repaglinide'].value_counts())\n",
    "print(df['nateglinide'].value_counts())\n",
    "print(df['chlorpropamide'].value_counts())\n",
    "print(df['glimepiride'].value_counts())\n",
    "print(df['acetohexamide'].value_counts())\n",
    "print(df['glipizide'].value_counts())\n",
    "print(df['glyburide'].value_counts())\n",
    "print(df['tolbutamide'].value_counts())\n",
    "print(df['pioglitazone'].value_counts())\n",
    "print(df['rosiglitazone'].value_counts())\n",
    "print(df['acarbose'].value_counts())\n",
    "print(df['miglitol'].value_counts())\n",
    "print(df['troglitazone'].value_counts())\n",
    "print(df['tolazamide'].value_counts())\n",
    "print(df['examide'].value_counts())\n",
    "print(df['citoglipton'].value_counts())\n",
    "print(df['insulin'].value_counts())\n",
    "print(df['glyburide-metformin'].value_counts())\n",
    "print(df['glipizide-metformin'].value_counts())\n",
    "print(df['glimepiride-pioglitazone'].value_counts())\n",
    "print(df['metformin-rosiglitazone'].value_counts())\n",
    "print(df['metformin-pioglitazone'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We drop the 15 medications that are barely taken or prescribed. We use the criteria that we only include the ones that are taken\n",
    "# or prescribed by at least 1% of patients.\n",
    "barely_used = ['nateglinide',\n",
    "               'chlorpropamide',\n",
    "               'acetohexamide',\n",
    "               'tolbutamide',\n",
    "               'acarbose',\n",
    "               'miglitol',\n",
    "               'troglitazone',\n",
    "               'tolazamide',\n",
    "               'examide',\n",
    "               'citoglipton',\n",
    "               'glyburide-metformin',\n",
    "               'glipizide-metformin',\n",
    "               'glimepiride-pioglitazone',\n",
    "               'metformin-rosiglitazone',\n",
    "               'metformin-pioglitazone'               \n",
    "              ]\n",
    "df = df.drop(columns = barely_used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We dummify each of the remaining eight medicine columns:\n",
    "used_medicine_strings = ['metformin',\n",
    "                         'repaglinide',\n",
    "                         'glimepiride',\n",
    "                         'glipizide',\n",
    "                         'glyburide',\n",
    "                         'pioglitazone',\n",
    "                         'rosiglitazone',\n",
    "                         'insulin']\n",
    "used_medicine_dfs = [df[medicine] for medicine in used_medicine_strings]\n",
    "\n",
    "for i in range(len(used_medicine_strings)):\n",
    "    used_medicine_dfs[i] = pd.get_dummies(df[used_medicine_strings[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each of the remaining medicines, the most common value is No, which stands for the medication not being taken or\n",
    "# prescribed. Since, we do not have any missingness for these columns, we can drop this most common value from the dummified\n",
    "# data frames.\n",
    "\n",
    "for medicine in used_medicine_dfs:\n",
    "    medicine = medicine.drop(columns = ['No'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we add the dummy columns back to the original dataframe and delete the original columns.\n",
    "df = pd.concat([df] + used_medicine_dfs, axis = 1)\n",
    "df = df.drop(columns = used_medicine_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lastly for the data cleaning process is to drop the two extraneous columns that record whether there was a change in diabetic\n",
    "# medicatin or if any diabetic medication was prescribed. These two columns are extraneous because the medicine columns that\n",
    "# we just added to the main df contain all the information from the extraneous ones.\n",
    "df = df.drop(columns=['change', 'diabetesMed'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['encounter_id',\n",
       " 'patient_nbr',\n",
       " 'age',\n",
       " 'time_in_hospital',\n",
       " 'num_lab_procedures',\n",
       " 'num_procedures',\n",
       " 'num_medications',\n",
       " 'number_outpatient',\n",
       " 'number_emergency',\n",
       " 'number_inpatient',\n",
       " 'number_diagnoses',\n",
       " 'readmitted',\n",
       " 'AfricanAmerican',\n",
       " 'Asian',\n",
       " 'Hispanic',\n",
       " 'Other',\n",
       " 'Male',\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 7,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 19,\n",
       " 20,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 27,\n",
       " 28,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 8,\n",
       " 10,\n",
       " 11,\n",
       " 13,\n",
       " 14,\n",
       " 22,\n",
       " 25,\n",
       " 'AllergyandImmunology',\n",
       " 'Anesthesiology',\n",
       " 'Anesthesiology-Pediatric',\n",
       " 'Cardiology-Pediatric',\n",
       " 'DCPTEAM',\n",
       " 'Dentistry',\n",
       " 'Dermatology',\n",
       " 'Endocrinology',\n",
       " 'Endocrinology-Metabolism',\n",
       " 'Gastroenterology',\n",
       " 'Gynecology',\n",
       " 'Hematology',\n",
       " 'Hematology/Oncology',\n",
       " 'Hospitalist',\n",
       " 'InfectiousDiseases',\n",
       " 'Neurology',\n",
       " 'Neurophysiology',\n",
       " 'Obsterics&Gynecology-GynecologicOnco',\n",
       " 'Obstetrics',\n",
       " 'ObstetricsandGynecology',\n",
       " 'Oncology',\n",
       " 'Ophthalmology',\n",
       " 'Osteopath',\n",
       " 'Otolaryngology',\n",
       " 'OutreachServices',\n",
       " 'Pathology',\n",
       " 'Pediatrics',\n",
       " 'Pediatrics-AllergyandImmunology',\n",
       " 'Pediatrics-CriticalCare',\n",
       " 'Pediatrics-EmergencyMedicine',\n",
       " 'Pediatrics-Endocrinology',\n",
       " 'Pediatrics-Hematology-Oncology',\n",
       " 'Pediatrics-InfectiousDiseases',\n",
       " 'Pediatrics-Neurology',\n",
       " 'Pediatrics-Pulmonology',\n",
       " 'Perinatology',\n",
       " 'PhysicalMedicineandRehabilitation',\n",
       " 'PhysicianNotFound',\n",
       " 'Podiatry',\n",
       " 'Proctology',\n",
       " 'Psychiatry',\n",
       " 'Psychiatry-Addictive',\n",
       " 'Psychiatry-Child/Adolescent',\n",
       " 'Psychology',\n",
       " 'Pulmonology',\n",
       " 'Radiology',\n",
       " 'Resident',\n",
       " 'Rheumatology',\n",
       " 'Speech',\n",
       " 'SportsMedicine',\n",
       " 'Surgeon',\n",
       " 'Surgery-Cardiovascular',\n",
       " 'Surgery-Cardiovascular/Thoracic',\n",
       " 'Surgery-Colon&Rectal',\n",
       " 'Surgery-Maxillofacial',\n",
       " 'Surgery-Neuro',\n",
       " 'Surgery-Pediatric',\n",
       " 'Surgery-Plastic',\n",
       " 'Surgery-PlasticwithinHeadandNeck',\n",
       " 'Surgery-Thoracic',\n",
       " 'Surgery-Vascular',\n",
       " 'SurgicalSpecialty',\n",
       " 'Urology',\n",
       " 'circulatory',\n",
       " 'diabetes',\n",
       " 'digestive',\n",
       " 'genitourinary',\n",
       " 'injury',\n",
       " 'musculoskeletal',\n",
       " 'neoplasms',\n",
       " 'other',\n",
       " 'respiratory',\n",
       " '>200',\n",
       " '>300',\n",
       " 'Norm',\n",
       " '>7',\n",
       " '>8',\n",
       " 'None',\n",
       " 'Norm',\n",
       " 'Down',\n",
       " 'No',\n",
       " 'Steady',\n",
       " 'Up',\n",
       " 'Down',\n",
       " 'No',\n",
       " 'Steady',\n",
       " 'Up',\n",
       " 'Down',\n",
       " 'No',\n",
       " 'Steady',\n",
       " 'Up',\n",
       " 'Down',\n",
       " 'No',\n",
       " 'Steady',\n",
       " 'Up',\n",
       " 'Down',\n",
       " 'No',\n",
       " 'Steady',\n",
       " 'Up',\n",
       " 'Down',\n",
       " 'No',\n",
       " 'Steady',\n",
       " 'Up',\n",
       " 'Down',\n",
       " 'No',\n",
       " 'Steady',\n",
       " 'Up',\n",
       " 'Down',\n",
       " 'No',\n",
       " 'Steady',\n",
       " 'Up']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "encounter_id          7556418\n",
       "patient_nbr           4282317\n",
       "age                         5\n",
       "time_in_hospital            6\n",
       "num_lab_procedures         57\n",
       "num_procedures              2\n",
       "num_medications            14\n",
       "number_outpatient           0\n",
       "number_emergency            0\n",
       "number_inpatient            0\n",
       "number_diagnoses            4\n",
       "readmitted                 NO\n",
       "AfricanAmerican             0\n",
       "Asian                       0\n",
       "Hispanic                    0\n",
       "Other                       0\n",
       "Male                        1\n",
       "2                           0\n",
       "3                           0\n",
       "4                           0\n",
       "7                           0\n",
       "2                           0\n",
       "3                           0\n",
       "4                           0\n",
       "5                           0\n",
       "6                           0\n",
       "7                           0\n",
       "8                           0\n",
       "9                           0\n",
       "10                          0\n",
       "                       ...   \n",
       "Steady                      0\n",
       "Up                          0\n",
       "Down                        0\n",
       "No                          1\n",
       "Steady                      0\n",
       "Up                          0\n",
       "Down                        0\n",
       "No                          1\n",
       "Steady                      0\n",
       "Up                          0\n",
       "Down                        0\n",
       "No                          0\n",
       "Steady                      1\n",
       "Up                          0\n",
       "Down                        0\n",
       "No                          1\n",
       "Steady                      0\n",
       "Up                          0\n",
       "Down                        0\n",
       "No                          1\n",
       "Steady                      0\n",
       "Up                          0\n",
       "Down                        0\n",
       "No                          1\n",
       "Steady                      0\n",
       "Up                          0\n",
       "Down                        0\n",
       "No                          1\n",
       "Steady                      0\n",
       "Up                          0\n",
       "Name: 1000, Length: 168, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[1000]\n",
    "#df.readmitted.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Put my new df into a csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
